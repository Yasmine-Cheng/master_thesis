{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "fa502430-289f-4b4f-b7c8-0ac45a2cf78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import ast\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LayerNorm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "83c7b6f3-572a-4605-a95b-4bd0aae25648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### read_csv\n",
    "\n",
    "data = pd.read_csv('./data/formal_data/Train_data/new_train.csv', usecols=['post_id', 'post_content', 'idx', 'response_content', 'topic', 'Advice', 'Agreement', 'Answer', 'Apology', 'AskHelp', 'Blessings', 'Command', 'Commitment', 'Concern', 'Decision', 'Denial', 'Deterrence', 'Emotion', 'Gratitude', 'Invitation', 'Malicious', 'Opinion', 'Persuasion', 'Refusal', 'Sarcasm', 'Sympathy'])\n",
    "data = data.sort_values(['post_id', 'idx'], ascending=[True, True])\n",
    "# data = data.head(5)\n",
    "data = data.reset_index()\n",
    "data = data[~data['post_id'].isin(list(set(data[data['Advice'].isna()]['post_id'].tolist())))]\n",
    "temp = data.groupby('post_id')['response_content'].apply(list).reset_index(name='response')['response'].tolist()\n",
    "new_temp = []\n",
    "for i in range(len(temp)):\n",
    "    temp[i].pop()\n",
    "    temp[i].insert(0, np.nan)\n",
    "    new_temp.append(temp[i])\n",
    "\n",
    "data['prev_response'] = list(itertools.chain(*new_temp))\n",
    "data['prev_response'] = data['prev_response'].fillna(data['post_content'])\n",
    "\n",
    "data = data[~data['post_id'].isin(list(set(data[data['Advice'].isna()]['post_id'].tolist())))]\n",
    "temp = data.groupby('post_id')['response_content'].apply(list).reset_index(name='response')['response'].tolist()\n",
    "new_temp = []\n",
    "for i in range(len(temp)):\n",
    "    temp[i].pop()\n",
    "    temp[i].insert(0, np.nan)\n",
    "    new_temp.append(temp[i])\n",
    "\n",
    "data['prev_response'] = list(itertools.chain(*new_temp))\n",
    "data['prev_response'] = data['prev_response'].fillna(data['post_content'])\n",
    "data['topic'] = data['topic'].apply(lambda x:' '.join(list(ast.literal_eval(x).keys())))\n",
    "data = data.astype(str)\n",
    "\n",
    "for i in data[['Advice', 'Agreement', 'Answer', 'Apology', 'AskHelp', 'Blessings', 'Command', 'Commitment', 'Concern', 'Decision', 'Denial', 'Deterrence', 'Emotion', 'Gratitude', 'Invitation', 'Malicious', 'Opinion', 'Persuasion', 'Refusal', 'Sarcasm', 'Sympathy']].columns:\n",
    "    data[i].replace('1.0', i, inplace=True)\n",
    "    data[i].replace('0.0', '', inplace=True)\n",
    "data[\"social\"] = data[['Advice', 'Agreement', 'Answer', 'Apology', 'AskHelp', 'Blessings', 'Command', 'Commitment', 'Concern', 'Decision', 'Denial', 'Deterrence', 'Emotion', 'Gratitude', 'Invitation', 'Malicious', 'Opinion', 'Persuasion', 'Refusal', 'Sarcasm', 'Sympathy']].agg(\" \".join, axis=1)\n",
    "\n",
    "data = data[['post_content', 'prev_response', 'response_content', 'topic', 'social']]\n",
    "data = data.rename(columns={\"post_content\": \"post\", \"response_content\": \"next_response\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "105e5e5b-573e-44e4-beb5-f85dc4238bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.post = data['post']\n",
    "        self.prev_response = data['prev_response']\n",
    "        self.next_response = data['next_response']\n",
    "        self.social = data['social']\n",
    "        self.topic = data['topic']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.post)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'post': self.post[idx], 'prev_response': self.prev_response[idx], 'next_response': self.next_response[idx], 'social': self.social[idx], 'topic': self.topic[idx]}\n",
    "\n",
    "# Create a custom dataset and data loaderx=\n",
    "dataset = CustomDataset(data)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=5, shuffle=True)\n",
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "c56b9ab0-7411-4b2c-817d-6bf8844a09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義生成器（Generator_process）\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 定義鑑別器（Discriminator_process）\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "5c3797d3-235b-4f48-b374-00d8a4cecd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_process:\n",
    "    def __init__(self, post, prev_sentence, next_sentence, social, topic):\n",
    "        self.input_dim = 768\n",
    "        self.hidden_dim = 256\n",
    "        self.prev_sentence = prev_sentence\n",
    "        self.next_sentence = next_sentence\n",
    "        self.post = post\n",
    "        self.social = social\n",
    "        self.topic = topic\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "    def last_hidden_states(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        return last_hidden_states\n",
    "    \n",
    "    class PriorMLP(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim):\n",
    "            super(Generator_process.PriorMLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_dim, input_dim * 2)  # output mean and log-variance\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    class RecogMLP(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim):\n",
    "            super(Generator_process.RecogMLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim * 2, hidden_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(hidden_dim, input_dim * 2)  # output mean and log-variance\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(Generator_process.MLP, self).__init__()\n",
    "            self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    class DecoderWithMLP(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim):\n",
    "            super(Generator_process.DecoderWithMLP, self).__init__()\n",
    "            self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
    "            self.mlp_layer = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "            self.activation = nn.ReLU()  # 使用ReLU激活函数\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.activation(self.hidden_layer(x))\n",
    "            x = self.mlp_layer(x)\n",
    "            x = self.output_layer(x)\n",
    "            return x\n",
    "            \n",
    "    def decode(self, result_decode):\n",
    "        final_decoder = Generator_process.DecoderWithMLP(self.input_dim, self.hidden_dim)\n",
    "        output = final_decoder(result_decode)\n",
    "        return output\n",
    "        \n",
    "    def topic_social(self, hidden_feature):\n",
    "        seq_length, hidden_size = hidden_feature.size(1), hidden_feature.size(2)\n",
    "        flatten_hidden_states = hidden_feature.view(-1, seq_length * hidden_size)\n",
    "        mlp_model = Generator_process.MLP(seq_length * hidden_size, 768)\n",
    "        output = mlp_model(flatten_hidden_states)\n",
    "        return output\n",
    "    \n",
    "    def priorNrecog(self):\n",
    "        prev_last_hidden_states = self.last_hidden_states(self.prev_sentence)\n",
    "        next_last_hidden_states = self.last_hidden_states(self.next_sentence)\n",
    "        # 初始化 MLP 模型\n",
    "        prior_mlp_model = self.PriorMLP(self.input_dim, self.hidden_dim)\n",
    "        recog_mlp_model = self.RecogMLP(self.input_dim, self.hidden_dim)\n",
    "        \n",
    "        # 取句子中的某個字的隱藏特徵 (假設取第1個字)\n",
    "        prev_hidden_feature = prev_last_hidden_states[0, 0, :]\n",
    "        next_hidden_feature = next_last_hidden_states[0, 0, :]\n",
    "        # 將兩個字的隱藏特徵串聯起來\n",
    "        combined_features = torch.cat((prev_hidden_feature, next_hidden_feature), dim=-1)\n",
    "        # 增加 batch 維度\n",
    "        prev_hidden_feature = prev_hidden_feature.unsqueeze(0)\n",
    "        combined_features = combined_features.unsqueeze(0)\n",
    "        # 計算 MLP 的輸出 (mean 和 log-variance)\n",
    "        prev_output = prior_mlp_model(prev_hidden_feature)\n",
    "        combined_output = recog_mlp_model(combined_features)\n",
    "        # 分離 mean 和 log-variance\n",
    "        prev_mean, prev_log_var = prev_output.chunk(2, dim=-1)\n",
    "        combined_mean, combined_log_var = combined_output.chunk(2, dim=-1)\n",
    "        # 計算標準差 (diagonal covariance)\n",
    "        prev_std = torch.exp(0.5 * prev_log_var)\n",
    "        combined_std = torch.exp(0.5 * combined_log_var)\n",
    "        linear_layer = nn.Linear(self.input_dim, self.input_dim)\n",
    "        prev_final_output = linear_layer(prev_mean)\n",
    "        combined_output = linear_layer(combined_mean)\n",
    "        return prev_hidden_feature, prev_final_output, combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "82c9439c-1c40-4fc7-b659-c4e5d2870312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_process:\n",
    "    def __init__(self, fake_response, prev_sentence, next_sentence):\n",
    "        self.fake_response = fake_response\n",
    "        self.prev_sentence = prev_sentence\n",
    "        self.next_sentence = next_sentence\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_size, output_size):\n",
    "            super(Discriminator_process.MLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, output_size)\n",
    "            self.relu = nn.ReLU()\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            return x\n",
    "    \n",
    "    class CNNMaxPoolingFeatureExtractor(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, kernel_size, pool_size):\n",
    "            super(Discriminator_process.CNNMaxPoolingFeatureExtractor, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "            self.pool = nn.MaxPool2d(pool_size, stride=pool_size)\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.pool(x)\n",
    "            return x\n",
    "    \n",
    "    class SimilarityScore(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(Discriminator_process.SimilarityScore, self).__init__()\n",
    "            self.fc = nn.Linear(input_size, 1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            x = self.fc(x)\n",
    "            x = self.sigmoid(x)\n",
    "            return x\n",
    "    \n",
    "    def mg(self):\n",
    "        mlp = Generator_process.MLP(768, self.prev_sentence.size()[1] * 768)\n",
    "        fake_response_mapped = mlp(self.fake_response).view(1, self.prev_sentence.size()[1], 768)\n",
    "        inner_product = torch.matmul(fake_response_mapped, self.prev_sentence.transpose(1, 2))\n",
    "        inner_product = inner_product.unsqueeze(1)\n",
    "        cnn_pool_extractor = CNNMaxPoolingFeatureExtractor(1, 10, (3, 3), (2, 2))\n",
    "        features = cnn_pool_extractor(inner_product)\n",
    "        features_flattened = features.view(features.size(0), -1)\n",
    "        similarity_model = SimilarityScore(features_flattened.size(1))\n",
    "        similarity_score = similarity_model(features_flattened)\n",
    "        return similarity_score\n",
    "        \n",
    "    def mt(self):\n",
    "        mlp = Generator_process.MLP(self.next_sentence.size()[1] * 768, self.prev_sentence.size()[1] * 768)  # 输入大小为A向量大小，输出大小为B向量大小\n",
    "        next_sentence_mapped = mlp(self.next_sentence.view(1, -1)).view(1, self.prev_sentence.size()[1], 768)\n",
    "        inner_product = torch.matmul(next_sentence_mapped, self.prev_sentence.transpose(1, 2))\n",
    "        inner_product = inner_product.unsqueeze(1)\n",
    "        cnn_pool_extractor = CNNMaxPoolingFeatureExtractor(1, 10, (3, 3), (2, 2))\n",
    "        features = cnn_pool_extractor(inner_product)\n",
    "        features_flattened = features.view(features.size(0), -1)\n",
    "        similarity_model = SimilarityScore(features_flattened.size(1))\n",
    "        similarity_score = similarity_model(features_flattened)\n",
    "        return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70be17a-0172-4800-be91-642f1b3c0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Generator Loss: 0.03695230931043625, Discriminator Loss: 0.6556451916694641\n",
      "Epoch [2/10], Generator Loss: 0.031797852367162704, Discriminator Loss: 4.029597282409668\n",
      "Epoch [3/10], Generator Loss: 0.04376428574323654, Discriminator Loss: 2.616647243499756\n",
      "Epoch [4/10], Generator Loss: 0.035848550498485565, Discriminator Loss: 0.7132371068000793\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import math\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.00005)\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for idx in range(len(data)):\n",
    "    # for idx in [0]:\n",
    "        result_vector = torch.zeros(1, 768)\n",
    "        \n",
    "        post = data['post'][idx]\n",
    "        prev_response = data['prev_response'][idx]\n",
    "        next_response = data['next_response'][idx]\n",
    "        social = data['social'][idx]\n",
    "        topic = data['topic'][idx]\n",
    "\n",
    "        generator_process = Generator_process(post, prev_response, next_response, social, topic)\n",
    "        prev_hidden_feature, prev_final_output, combined_output = generator_process.priorNrecog()\n",
    "        post_hidden_feature = generator_process.last_hidden_states(post)[0, 0, :].unsqueeze(0)\n",
    "\n",
    "        prev_response_hidden_feature = generator_process.last_hidden_states(prev_response)\n",
    "        next_response_hidden_feature = generator_process.last_hidden_states(next_response)\n",
    "        \n",
    "        social_hidden_feature = generator_process.last_hidden_states(social)\n",
    "        social_hidden_feature = generator_process.topic_social(social_hidden_feature)\n",
    "        topic_hidden_feature = generator_process.last_hidden_states(topic)\n",
    "        topic_hidden_feature = generator_process.topic_social(topic_hidden_feature)\n",
    "\n",
    "        # 進行特徵向量之間的 ⊕ 運算\n",
    "        for vector in [prev_hidden_feature, prev_final_output, combined_output, post_hidden_feature, social_hidden_feature, topic_hidden_feature]:\n",
    "            result_vector += vector\n",
    "        fake_response = generator_process.decode(result_vector)\n",
    " \n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        discriminator_process = Discriminator_process(fake_response, prev_response_hidden_feature, next_response_hidden_feature)\n",
    "        mg = discriminator_process.mg()\n",
    "        mt = discriminator_process.mt()\n",
    "        d_loss = -(torch.log(mt) + torch.log(1 - mg)).mean()\n",
    "        d_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "    # 訓練生成器\n",
    "    generator.zero_grad\n",
    "    kl_div =  F.kl_div(F.log_softmax(prev_final_output, dim=-1), F.softmax(combined_output, dim=-1), reduction='batchmean')\n",
    "    reconstruction_term = F.mse_loss(prev_final_output, combined_output)\n",
    "    g_loss = kl_div + reconstruction_term\n",
    "    g_loss = torch.tensor(g_loss.item(), requires_grad=True)\n",
    "    g_loss.backward()\n",
    "    optimizer_generator.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938fc30-d12a-4ded-b454-869f0d1f246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
